# ğŸ§  Multi-Agent RAG Research Assistant

A modular, multi-agent research assistant built with LangChain and Streamlit. This app retrieves academic content from PDFs, summarizes the information, verifies it, and generates a final, clean answer â€” all with the help of AI agents.

---

## ğŸ“ Project Structure

```bash
multi_agent_rag/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ retriever.py        # Retrieves relevant chunks using vector search
â”‚   â”œâ”€â”€ summarizer.py       # Summarizes the retrieved content
â”‚   â”œâ”€â”€ verifier.py         # Verifies the summary for factual accuracy
â”‚   â””â”€â”€ synthesizer.py      # Synthesizes a final answer using the summary + verification
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_papers/
â”‚       â””â”€â”€ paper1.pdf      # Add academic PDFs here
â”œâ”€â”€ ingest.py               # Loads, splits, and indexes the PDFs
â”œâ”€â”€ app.py                  # Streamlit frontend for research Q&A
â”œâ”€â”€ requirements.txt        # Python dependencies
```

---

## ğŸš€ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/samyakshrma/multi_agent_rag.git
cd multi_agent_rag
```

### 2. Create and Activate Virtual Environment

```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
pip install -U langchain-openai langchain-community
```

### 4. Add Your OpenAI API Key

**Option A (Recommended):**
```bash
export OPENAI_API_KEY="your-api-key-here"
```

**Option B (Alternative - Inline):**
Edit `app.py` and provide your key:
```python
OpenAI(temperature=0, openai_api_key="your-api-key-here")
```

---

## ğŸ“„ Usage

### 1. Index Your PDF Documents

Place your academic PDFs into the `data/sample_papers/` folder, then run:

```bash
python ingest.py
```

This will:
- Load PDFs
- Split text into chunks
- Generate embeddings
- Store them in a Chroma vector database

### 2. Launch the Streamlit App

```bash
streamlit run app.py
```

Open the app in your browser at:
```
http://localhost:8501
```

Enter a research question, and the assistant will:
1. Retrieve relevant content from PDFs
2. Summarize the findings
3. Verify the summary
4. Generate a well-structured final answer

---

## ğŸ§© Agents Overview

Each agent is defined in the `agents/` directory and serves a dedicated purpose:

| Agent        | Description |
|--------------|-------------|
| **Retriever** | Performs vector-based similarity search from indexed chunks |
| **Summarizer** | Summarizes the content using an LLM |
| **Verifier** | Checks for factual accuracy and highlights gaps |
| **Synthesizer** | Composes a refined final answer using summary + verification |

---

## âœ… Tech Stack

- **LangChain**: Agent-based framework for LLM apps
- **HuggingFace Transformers**: For text embeddings
- **ChromaDB**: Local vector database
- **Streamlit**: UI for interacting with the system
- **OpenAI API**: Language model backend (customizable)

---

## ğŸ›  Future Enhancements

- âœ… Local LLM support (e.g., Ollama, LLaMA)
- ğŸ“„ Citation support (link to sources)
- ğŸ§  Memory support via LangChain's ConversationBuffer
- ğŸ“ˆ Result visualization (charts, graphs, etc.)

---
